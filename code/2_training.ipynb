{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60a9080b",
   "metadata": {},
   "source": [
    "### ToDo\n",
    "- Train Random Forest as a baseline for each assay in the validation and test splits. For each assay, a support set of ten data points (5 active and 5 inactive molecules) will be created, on which the Random Forest will be trained, and a query set will be used to evaluate the predictions.\n",
    "- Train Neural Network as a Frequent Model: All training assays will be aggregated into a pool. The neural network (Feedforward Neural Network) will be trained based on the aggregated data to achieve the best possible performance on the validation set.\n",
    "- Compare the performance of the models using AUC. For Random Forest, calculate AUC for every assay and then take the mean. For NN, ???\n",
    "- Filtering NaN Values: Molecules with missing values (NaN) will be removed from the training pool. The neural network will only be trained with valid data, and only molecules with labels (0 or 1) will be considered in the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b91d66",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81bbf12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "12.4\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from itertools import product\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from rdkit import Chem\n",
    "\n",
    "\n",
    "#from IPython.core.display import display, HTML\n",
    "#display(HTML(\"<style>.container { width:80% !important; }</style>\"))\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.version.cuda)  # Check PyTorch's CUDA version\n",
    "print(torch.cuda.device_count())  # Number of GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be562f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[03:11:09] WARNING: not removing hydrogen atom without neighbors\n",
      "[03:11:11] WARNING: not removing hydrogen atom without neighbors\n",
      "[03:11:12] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    }
   ],
   "source": [
    "# Load from pickle file\n",
    "with open(\"datasets/datasets.pkl\", \"rb\") as f:\n",
    "    datasets = pd.read_pickle(f)\n",
    "\n",
    "# Extract individual DataFrames\n",
    "train_set_import = datasets[\"train\"]\n",
    "validation_set_import = datasets[\"validation\"]\n",
    "test_set_import = datasets[\"test\"]\n",
    "\n",
    "# Convert SMILES strings back to RDKit molecule objects\n",
    "def postprocess_from_pickle(df):\n",
    "    df = df.copy()\n",
    "    df['molecule'] = df['molecule'].apply(lambda smiles: Chem.MolFromSmiles(smiles) if smiles else None)\n",
    "    return df\n",
    "\n",
    "# Apply postprocessing\n",
    "train_set = postprocess_from_pickle(train_set_import)\n",
    "validation_set = postprocess_from_pickle(validation_set_import)\n",
    "test_set = postprocess_from_pickle(test_set_import)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "604e4731",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>molecule</th>\n",
       "      <th>quantilesXecfps</th>\n",
       "      <th>ATG_AR_TRANS_dn</th>\n",
       "      <th>TOX21_p53_BLA_p1_ratio</th>\n",
       "      <th>ATG_FoxA2_CIS_up</th>\n",
       "      <th>BSK_hDFCGF_TIMP1_down</th>\n",
       "      <th>ATG_LXRb_TRANS_up</th>\n",
       "      <th>Tanguay_ZF_120hpf_JAW_up</th>\n",
       "      <th>BSK_LPS_IL8_up</th>\n",
       "      <th>NVS_ADME_hCYP2D6</th>\n",
       "      <th>...</th>\n",
       "      <th>TOX21_ERa_BLA_Antagonist_ch1</th>\n",
       "      <th>NVS_ENZ_oCOX2</th>\n",
       "      <th>TOX21_ARE_BLA_Agonist_ch2</th>\n",
       "      <th>BSK_LPS_CD40_down</th>\n",
       "      <th>TOX21_Aromatase_Inhibition</th>\n",
       "      <th>BSK_hDFCGF_MCSF_down</th>\n",
       "      <th>ATG_RARa_TRANS_up</th>\n",
       "      <th>BSK_LPS_IL1a_up</th>\n",
       "      <th>TOX21_ESRE_BLA_ratio</th>\n",
       "      <th>NVS_ENZ_hBACE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x000001C6AEA...</td>\n",
       "      <td>[1.3356484982591836, 1.3356484982591836, -0.38...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x000001C6AEA...</td>\n",
       "      <td>[0.9840356627736608, 0.9840356627736608, 0.100...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x000001C6AEA...</td>\n",
       "      <td>[1.4329130642502799, 1.4329130642502799, -0.37...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x000001C6AEA...</td>\n",
       "      <td>[1.3424432672295052, 1.3424432672295052, -0.39...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x000001C6AEA...</td>\n",
       "      <td>[1.303283942956551, 1.303283942956551, -0.3673...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 372 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            molecule  \\\n",
       "0  <rdkit.Chem.rdchem.Mol object at 0x000001C6AEA...   \n",
       "1  <rdkit.Chem.rdchem.Mol object at 0x000001C6AEA...   \n",
       "2  <rdkit.Chem.rdchem.Mol object at 0x000001C6AEA...   \n",
       "3  <rdkit.Chem.rdchem.Mol object at 0x000001C6AEA...   \n",
       "4  <rdkit.Chem.rdchem.Mol object at 0x000001C6AEA...   \n",
       "\n",
       "                                     quantilesXecfps  ATG_AR_TRANS_dn  \\\n",
       "0  [1.3356484982591836, 1.3356484982591836, -0.38...              0.0   \n",
       "1  [0.9840356627736608, 0.9840356627736608, 0.100...              NaN   \n",
       "2  [1.4329130642502799, 1.4329130642502799, -0.37...              NaN   \n",
       "3  [1.3424432672295052, 1.3424432672295052, -0.39...              0.0   \n",
       "4  [1.303283942956551, 1.303283942956551, -0.3673...              0.0   \n",
       "\n",
       "   TOX21_p53_BLA_p1_ratio  ATG_FoxA2_CIS_up  BSK_hDFCGF_TIMP1_down  \\\n",
       "0                     0.0               0.0                    0.0   \n",
       "1                     0.0               NaN                    NaN   \n",
       "2                     0.0               NaN                    NaN   \n",
       "3                     0.0               0.0                    0.0   \n",
       "4                     0.0               0.0                    0.0   \n",
       "\n",
       "   ATG_LXRb_TRANS_up  Tanguay_ZF_120hpf_JAW_up  BSK_LPS_IL8_up  \\\n",
       "0                0.0                       0.0             0.0   \n",
       "1                NaN                       NaN             NaN   \n",
       "2                NaN                       NaN             NaN   \n",
       "3                0.0                       0.0             0.0   \n",
       "4                0.0                       0.0             0.0   \n",
       "\n",
       "   NVS_ADME_hCYP2D6  ...  TOX21_ERa_BLA_Antagonist_ch1  NVS_ENZ_oCOX2  \\\n",
       "0               NaN  ...                           0.0            1.0   \n",
       "1               NaN  ...                           0.0            NaN   \n",
       "2               NaN  ...                           0.0            NaN   \n",
       "3               NaN  ...                           0.0            NaN   \n",
       "4               0.0  ...                           0.0            NaN   \n",
       "\n",
       "   TOX21_ARE_BLA_Agonist_ch2  BSK_LPS_CD40_down  TOX21_Aromatase_Inhibition  \\\n",
       "0                        0.0                0.0                         0.0   \n",
       "1                        0.0                NaN                         0.0   \n",
       "2                        0.0                NaN                         0.0   \n",
       "3                        0.0                0.0                         0.0   \n",
       "4                        0.0                0.0                         0.0   \n",
       "\n",
       "   BSK_hDFCGF_MCSF_down  ATG_RARa_TRANS_up  BSK_LPS_IL1a_up  \\\n",
       "0                   0.0                0.0              0.0   \n",
       "1                   NaN                NaN              NaN   \n",
       "2                   NaN                NaN              NaN   \n",
       "3                   0.0                0.0              0.0   \n",
       "4                   0.0                0.0              0.0   \n",
       "\n",
       "   TOX21_ESRE_BLA_ratio  NVS_ENZ_hBACE  \n",
       "0                   0.0            NaN  \n",
       "1                   0.0            NaN  \n",
       "2                   0.0            NaN  \n",
       "3                   0.0            NaN  \n",
       "4                   0.0            NaN  \n",
       "\n",
       "[5 rows x 372 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ab8fcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dauprc_score(predictions, labels, target_ids):\n",
    "    \"\"\"\n",
    "    Computes the Î”AUC-PR score for each target separately and the mean Î”AUC-PR score.\n",
    "    \"\"\"\n",
    "    dauprcs = list()\n",
    "    target_id_list = list()\n",
    "\n",
    "    for target_idx in torch.unique(target_ids):\n",
    "        rows = torch.where(target_ids == target_idx)\n",
    "        preds = predictions[rows].detach()\n",
    "        y = labels[rows].int()\n",
    "\n",
    "        if torch.unique(y).shape[0] == 2:\n",
    "            number_actives = y[y == 1].shape[0]\n",
    "            number_inactives = y[y == 0].shape[0]\n",
    "            number_total = number_actives + number_inactives\n",
    "\n",
    "            random_clf_auprc = number_actives / number_total\n",
    "            auprc = average_precision_score(\n",
    "                y.numpy().flatten(), preds.numpy().flatten()\n",
    "            )\n",
    "\n",
    "            dauprc = auprc - random_clf_auprc\n",
    "            dauprcs.append(dauprc)\n",
    "            target_id_list.append(target_idx.item())\n",
    "        else:\n",
    "            dauprcs.append(np.nan)\n",
    "            target_id_list.append(target_idx.item())\n",
    "\n",
    "    return np.nanmean(dauprcs), dauprcs, target_id_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1821194",
   "metadata": {},
   "source": [
    "### Training & Evaluation Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fcc6a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(train_function, train_data, seeds, **kwargs):\n",
    "    seed_results = {}\n",
    "\n",
    "    for seed in seeds:\n",
    "        print(f\"Evaluating with seed {seed}...\")\n",
    "        np.random.seed(seed)  # Set seed fÃ¼r Reproduzierbarkeit\n",
    "        results, overall_mean_auc, overall_std_auc, overall_mean_dauprc, overall_std_dauprc = train_function(train_data, **kwargs)\n",
    "        \n",
    "        seed_results[seed] = {\n",
    "            'mean_auc': overall_mean_auc,\n",
    "            'std_auc': overall_std_auc,\n",
    "            'mean_dauprc': overall_mean_dauprc,\n",
    "            'std_dauprc': overall_std_dauprc,  # Neu: Standardabweichung Î”AUC-PR\n",
    "            'results': results\n",
    "        }\n",
    "\n",
    "    # Aggregierte Ergebnisse Ã¼ber alle Seeds berechnen\n",
    "    all_mean_aucs = [res['mean_auc'] for res in seed_results.values()]\n",
    "    all_std_aucs = [res['std_auc'] for res in seed_results.values()]\n",
    "    all_mean_dauprcs = [res['mean_dauprc'] for res in seed_results.values()]\n",
    "    all_std_dauprcs = [res['std_dauprc'] for res in seed_results.values()]\n",
    "\n",
    "    overall_mean_auc = np.mean(all_mean_aucs)\n",
    "    overall_std_auc = np.mean(all_std_aucs)\n",
    "    overall_mean_dauprc = np.mean(all_mean_dauprcs)\n",
    "    overall_std_dauprc = np.mean(all_std_dauprcs)  # Neu: Gesamt-Std fÃ¼r Î”AUC-PR\n",
    "\n",
    "    # Erstelle eine Zusammenfassung als DataFrame\n",
    "    summary_df = pd.DataFrame(\n",
    "        data={'Training Method': ['Random Forest'], \n",
    "              'Mean AUC': [f\"{overall_mean_auc:.4f}\"],\n",
    "              'Std AUC': [f\"{overall_std_auc:.4f}\"],\n",
    "              'Mean Î”AUC-PR': [f\"{overall_mean_dauprc:.4f}\"],\n",
    "              'Std Î”AUC-PR': [f\"{overall_std_dauprc:.4f}\"]})  # Neu: Std Î”AUC-PR\n",
    "\n",
    "    # Drucken der Zusammenfassung\n",
    "    print(\"\\nSummary of Results:\")\n",
    "    print(summary_df.to_string(index=False))\n",
    "\n",
    "    return seed_results, summary_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48191d72",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1f82816",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(train_data, n_episodes=5):\n",
    "    assay_columns = [col for col in train_data.columns \n",
    "                     if col not in ['molecule', 'quantilesXecfps']]\n",
    "    \n",
    "    assay_results = {}\n",
    "    total_assays = len(assay_columns)\n",
    "\n",
    "    with tqdm(total=total_assays, desc=\"Training Assays\") as pbar:\n",
    "        for assay in assay_columns:\n",
    "            pbar.set_postfix(current_assay=assay)\n",
    "\n",
    "            # Entferne NaN-Werte im aktuellen Assay\n",
    "            assay_data = train_data.dropna(subset=[assay])\n",
    "            positive_samples = assay_data[assay_data[assay] == 1]\n",
    "            negative_samples = assay_data[assay_data[assay] == 0]\n",
    "\n",
    "            if len(positive_samples) < 5 or len(negative_samples) < 5:\n",
    "                pbar.update(1)\n",
    "                continue\n",
    "\n",
    "            episode_aucs = []\n",
    "            episode_dauprcs = []  # Hier sammeln wir alle Î”AUC-PR Werte\n",
    "\n",
    "            for _ in range(n_episodes):\n",
    "                # Sample Support-Set\n",
    "                support_pos = positive_samples.sample(n=5)\n",
    "                support_neg = negative_samples.sample(n=5)\n",
    "                support_set = pd.concat([support_pos, support_neg])\n",
    "\n",
    "                # Erstelle das Query-Set (Rest der Daten)\n",
    "                query_set = assay_data.drop(support_set.index)\n",
    "\n",
    "                # Features und Labels vorbereiten\n",
    "                X_support = np.stack(support_set['quantilesXecfps'].values)\n",
    "                y_support = support_set[assay].values\n",
    "                X_query = np.stack(query_set['quantilesXecfps'].values)\n",
    "                y_query = query_set[assay].values\n",
    "\n",
    "                # Trainiere den Random Forest\n",
    "                rf = RandomForestClassifier(random_state=None) # Place seed here\n",
    "                rf.fit(X_support, y_support)\n",
    "\n",
    "                # Evaluieren auf Query-Set\n",
    "                y_pred = rf.predict_proba(X_query)[:, 1]\n",
    "\n",
    "                # Berechnung von ROC-AUC\n",
    "                episode_auc = roc_auc_score(y_query, y_pred)\n",
    "                episode_aucs.append(episode_auc)\n",
    "\n",
    "                # Berechnung von Î”AUC-PR\n",
    "                y_tensor = torch.tensor(y_query)\n",
    "                preds_tensor = torch.tensor(y_pred)\n",
    "                target_ids = torch.full_like(y_tensor, fill_value=assay_columns.index(assay), dtype=torch.int64)\n",
    "                _, dauprc, _ = compute_dauprc_score(preds_tensor, y_tensor, target_ids)\n",
    "                episode_dauprcs.append(dauprc)\n",
    "\n",
    "            # Berechne den Mittelwert und die Standardabweichung fÃ¼r AUC und Î”AUC-PR\n",
    "            mean_assay_auc = np.mean(episode_aucs)\n",
    "            std_assay_auc = np.std(episode_aucs)\n",
    "            mean_assay_dauprc = np.mean(episode_dauprcs)\n",
    "            std_assay_dauprc = np.std(episode_dauprcs)\n",
    "\n",
    "            assay_results[assay] = {\n",
    "                'mean_auc': mean_assay_auc,\n",
    "                'std_auc': std_assay_auc,\n",
    "                'mean_dauprc': mean_assay_dauprc,\n",
    "                'std_dauprc': std_assay_dauprc,  # Neu: Standardabweichung Î”AUC-PR\n",
    "                'episode_aucs': episode_aucs,\n",
    "                'episode_dauprcs': episode_dauprcs,  \n",
    "            }\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "    # Gesamtwerte Ã¼ber alle Assays berechnen\n",
    "    overall_mean_auc = np.mean([res['mean_auc'] for res in assay_results.values()])\n",
    "    overall_std_auc = np.std([res['mean_auc'] for res in assay_results.values()])\n",
    "    overall_mean_dauprc = np.mean([res['mean_dauprc'] for res in assay_results.values()])\n",
    "    overall_std_dauprc = np.std([res['mean_dauprc'] for res in assay_results.values()])\n",
    "\n",
    "    print(f\"Overall Mean AUC across assays: {overall_mean_auc:.4f} Â± {overall_std_auc:.4f}\")\n",
    "    print(f\"Overall Mean Î”AUC-PR across assays: {overall_mean_dauprc:.4f} Â± {overall_std_dauprc:.4f}\")\n",
    "    print(\"=====================================================================\")\n",
    "    print(\"\")\n",
    "\n",
    "    return assay_results, overall_mean_auc, overall_std_auc, overall_mean_dauprc, overall_std_dauprc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29895d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating with seed 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Assays:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 114/123 [02:00<00:08,  1.05it/s, current_assay=ATG_Sp1_CIS_dn]                   "
     ]
    }
   ],
   "source": [
    "seeds = [0, 11942094, 23884188, 35826282, 47768376]\n",
    "seed_results, summary_table = train_and_evaluate(\n",
    "    train_function=random_forest,  # Pass your training function\n",
    "    train_data=validation_set,  # Pass your dataset\n",
    "    seeds=seeds,\n",
    "    n_episodes=5  # Additional arguments for the training function\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e542214b",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d3adb63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Assays: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 123/123 [01:01<00:00,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Mean AUC: 0.5553 Â± 0.0000\n",
      "Overall Mean Î”AUC-PR: 0.1498 Â± 0.0374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Set fixed seed for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# Define the Frequent Hitters model with customizable hyperparameters\n",
    "class FrequentHittersModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_layers=1, hidden_units=1024, dropout=0.4, layer_norm=False):\n",
    "        super(FrequentHittersModel, self).__init__()\n",
    "        layers = []\n",
    "        for _ in range(hidden_layers):\n",
    "            layers.append(nn.Linear(input_dim, hidden_units))\n",
    "            if layer_norm:\n",
    "                layers.append(nn.LayerNorm(hidden_units))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "            input_dim = hidden_units\n",
    "        layers.append(nn.Linear(input_dim, 1))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.model(x))\n",
    "\n",
    "# Function to train Frequent Hitters Model and compute AUC & Î”AUC-PR\n",
    "def train_frequent_hitters(train_data, hyperparam_grid, seed=42):\n",
    "    set_seed(seed)\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    assay_columns = [col for col in train_data.columns if col not in ['molecule', 'quantilesXecfps']]\n",
    "    assay_results = {}\n",
    "    best_model_params = None\n",
    "    best_overall_auc = 0\n",
    "\n",
    "    with tqdm(total=len(assay_columns), desc=\"Training Assays\") as pbar:\n",
    "        for assay in assay_columns:\n",
    "            train_assay_data = train_data.dropna(subset=[assay])\n",
    "            positive_samples = train_assay_data[train_assay_data[assay] == 1]\n",
    "            negative_samples = train_assay_data[train_assay_data[assay] == 0]\n",
    "\n",
    "            if len(positive_samples) < 5 or len(negative_samples) < 5:\n",
    "                pbar.update(1)\n",
    "                continue\n",
    "\n",
    "            best_assay_auc = 0\n",
    "            best_assay_params = None\n",
    "            episode_aucs = []\n",
    "            episode_dauprcs = []\n",
    "\n",
    "            for hyperparams in product(*hyperparam_grid.values()):\n",
    "                hyperparams_dict = dict(zip(hyperparam_grid.keys(), hyperparams))\n",
    "\n",
    "                for _ in range(5):  # 5 episodes\n",
    "                    support_pos = positive_samples.sample(n=5, random_state=random.randint(0, 10000))\n",
    "                    support_neg = negative_samples.sample(n=5, random_state=random.randint(0, 10000))\n",
    "                    support_set = pd.concat([support_pos, support_neg])\n",
    "                    query_set = train_assay_data.drop(support_set.index)\n",
    "\n",
    "                    X_support = torch.tensor(np.stack(support_set['quantilesXecfps'].values), dtype=torch.float32).to(device)\n",
    "                    y_support = torch.tensor(support_set[assay].values, dtype=torch.float32).to(device)\n",
    "                    X_query = torch.tensor(np.stack(query_set['quantilesXecfps'].values), dtype=torch.float32).to(device)\n",
    "                    y_query = torch.tensor(query_set[assay].values, dtype=torch.float32).to(device)\n",
    "\n",
    "                    model = FrequentHittersModel(\n",
    "                        input_dim=X_query.shape[1],\n",
    "                        hidden_layers=hyperparams_dict['hidden_layers'],\n",
    "                        hidden_units=hyperparams_dict['hidden_units'],\n",
    "                        dropout=hyperparams_dict['dropout'],\n",
    "                        layer_norm=hyperparams_dict['layer_norm']\n",
    "                    ).to(device)\n",
    "\n",
    "                    criterion = nn.BCELoss()\n",
    "                    optimizer = optim.Adam(model.parameters(), lr=hyperparams_dict['learning_rate'], weight_decay=hyperparams_dict['weight_decay'])\n",
    "\n",
    "                    model.train()\n",
    "                    for epoch in range(hyperparams_dict['epochs']):\n",
    "                        optimizer.zero_grad()\n",
    "                        outputs = model(X_query)\n",
    "                        loss = criterion(outputs, y_query.unsqueeze(1))\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                    # Evaluate on support set\n",
    "                    model.eval()\n",
    "                    with torch.no_grad():\n",
    "                        y_pred = model(X_support).cpu().numpy().squeeze()\n",
    "\n",
    "                    # Compute AUC\n",
    "                    episode_auc = roc_auc_score(y_support.cpu(), y_pred)\n",
    "                    episode_aucs.append(episode_auc)\n",
    "\n",
    "                    # Compute Î”AUC-PR\n",
    "                    target_ids = torch.zeros_like(y_support.cpu(), dtype=torch.int64) # Fix this\n",
    "                    _, dauprc, _ = compute_dauprc_score(torch.tensor(y_pred), y_support.cpu(), target_ids)\n",
    "                    episode_dauprcs.append(dauprc)\n",
    "\n",
    "                # Compute mean and std for AUC and Î”AUC-PR\n",
    "                mean_assay_auc = np.mean(episode_aucs)\n",
    "                std_assay_auc = np.std(episode_aucs)\n",
    "                mean_assay_dauprc = np.nanmean(episode_dauprcs)  # Avoid NaN issues\n",
    "                std_assay_dauprc = np.nanstd(episode_dauprcs)\n",
    "\n",
    "                if mean_assay_auc > best_assay_auc:\n",
    "                    best_assay_auc = mean_assay_auc\n",
    "                    best_assay_params = hyperparams_dict\n",
    "\n",
    "                    if mean_assay_auc > best_overall_auc:\n",
    "                        best_overall_auc = mean_assay_auc\n",
    "                        best_model_params = hyperparams_dict\n",
    "\n",
    "            assay_results[assay] = {\n",
    "                'best_params': best_assay_params,\n",
    "                'best_auc': best_assay_auc,\n",
    "                'mean_dauprc': mean_assay_dauprc,\n",
    "                'std_dauprc': std_assay_dauprc\n",
    "            }\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "    # Compute overall metrics\n",
    "    all_mean_aucs = [res['best_auc'] for res in assay_results.values()]\n",
    "    all_std_aucs = [np.std(res['best_auc']) for res in assay_results.values()]\n",
    "    all_mean_dauprcs = [res['mean_dauprc'] for res in assay_results.values()]\n",
    "    all_std_dauprcs = [res['std_dauprc'] for res in assay_results.values()]\n",
    "\n",
    "    overall_mean_auc = np.mean(all_mean_aucs)\n",
    "    overall_std_auc = np.std(all_std_aucs)\n",
    "    overall_mean_dauprc = np.nanmean(all_mean_dauprcs)\n",
    "    overall_std_dauprc = np.nanstd(all_std_dauprcs)\n",
    "\n",
    "    print(f\"Overall Mean AUC: {overall_mean_auc:.4f} Â± {overall_std_auc:.4f}\")\n",
    "    print(f\"Overall Mean Î”AUC-PR: {overall_mean_dauprc:.4f} Â± {overall_std_dauprc:.4f}\")\n",
    "\n",
    "    return assay_results, best_model_params, overall_mean_auc, overall_std_auc, overall_mean_dauprc, overall_std_dauprc\n",
    "\n",
    "\n",
    "# Example usage\n",
    "hyperparam_grid = {\n",
    "    'hidden_layers': [1],\n",
    "    'hidden_units': [1024],\n",
    "    'dropout': [0.5],\n",
    "    'layer_norm': [False],\n",
    "    'learning_rate': [0.001],\n",
    "    'weight_decay': [0],\n",
    "    'batch_size': [128],\n",
    "    'epochs': [5]\n",
    "}\n",
    "\n",
    "results, best_model_params, overall_mean_auc, overall_std_auc, overall_mean_dauprc, overall_std_dauprc = train_frequent_hitters(validation_set, hyperparam_grid, seed=12440)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4909cd02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hidden_layers': 1,\n",
       " 'hidden_units': 1024,\n",
       " 'dropout': 0.5,\n",
       " 'layer_norm': False,\n",
       " 'learning_rate': 0.001,\n",
       " 'weight_decay': 0,\n",
       " 'batch_size': 128,\n",
       " 'epochs': 5}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6ec324",
   "metadata": {},
   "source": [
    "### Hyperparameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf57a13b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78e93cc2",
   "metadata": {},
   "source": [
    "### Seed Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661e1122",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801d3096",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6564e9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparam_grid = {\n",
    "    'hidden_layers': [1, 2, 4],\n",
    "    'hidden_units': [1024, 2048],\n",
    "    'dropout': [0.4, 0.6],\n",
    "    'layer_norm': [False, True],\n",
    "    'learning_rate': [0.0001, 0.001],\n",
    "    'weight_decay': [0, 0.01],\n",
    "    'batch_size': [128, 512],\n",
    "    'epochs': [30]\n",
    "}\n",
    "hyperparam_grid = {\n",
    "    'hidden_layers': [1],\n",
    "    'hidden_units': [1024],\n",
    "    'dropout': [0.1],\n",
    "    'layer_norm': [False],\n",
    "    'learning_rate': [0.001],\n",
    "    'weight_decay': [0],\n",
    "    'batch_size': [128],\n",
    "    'epochs': [30]\n",
    "}\n",
    "seeds = [0, 11942094, 23884188, 35826282, 47768376]\n",
    "seeds = [0]\n",
    "results = train_all_assays(train_set, validation_set, test_set, hyperparam_grid, seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "086db248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No CUDA GPUs are available",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count())\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_device_name\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\Morad\\miniconda3\\envs\\fsmol2\\Lib\\site-packages\\torch\\cuda\\__init__.py:493\u001b[0m, in \u001b[0;36mget_device_name\u001b[1;34m(device)\u001b[0m\n\u001b[0;32m    481\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_device_name\u001b[39m(device: Optional[_device_t] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m    482\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Get the name of a device.\u001b[39;00m\n\u001b[0;32m    483\u001b[0m \n\u001b[0;32m    484\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    491\u001b[0m \u001b[38;5;124;03m        str: the name of the device\u001b[39;00m\n\u001b[0;32m    492\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 493\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_device_properties\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mname\n",
      "File \u001b[1;32mc:\\Users\\Morad\\miniconda3\\envs\\fsmol2\\Lib\\site-packages\\torch\\cuda\\__init__.py:523\u001b[0m, in \u001b[0;36mget_device_properties\u001b[1;34m(device)\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_device_properties\u001b[39m(device: _device_t) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _CudaDeviceProperties:\n\u001b[0;32m    514\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Get the properties of a device.\u001b[39;00m\n\u001b[0;32m    515\u001b[0m \n\u001b[0;32m    516\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    521\u001b[0m \u001b[38;5;124;03m        _CudaDeviceProperties: the properties of the device\u001b[39;00m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 523\u001b[0m     \u001b[43m_lazy_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# will define _get_device_properties\u001b[39;00m\n\u001b[0;32m    524\u001b[0m     device \u001b[38;5;241m=\u001b[39m _get_device_index(device, optional\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    525\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m device \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m device_count():\n",
      "File \u001b[1;32mc:\\Users\\Morad\\miniconda3\\envs\\fsmol2\\Lib\\site-packages\\torch\\cuda\\__init__.py:319\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[0;32m    318\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 319\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[0;32m    323\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe64c294",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80969b59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bae3b67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fsmol2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
